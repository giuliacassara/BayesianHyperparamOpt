{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Iris_Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliacern/HyperfMNIST/blob/master/Iris_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPHkMlJK45dT",
        "colab_type": "code",
        "outputId": "467f0561-7edc-4fdf-d765-ba917bf9fd20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaIDJkS44seh",
        "colab_type": "code",
        "outputId": "0e65708f-fd25-49d6-ccff-e335512ed8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install GPyOpt\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.0.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPyOpt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/be/669d505416d7e465b2aef7df3b58d590f56468c4f7dc50c91fe91b8a78d9/GPyOpt-1.2.6.tar.gz (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GPyOpt) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from GPyOpt) (1.4.1)\n",
            "Collecting GPy>=1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/976598f98adbfa918a480cb2d643f93fb555ca5b6c5614f76b69678114c1/GPy-1.9.9.tar.gz (995kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy>=1.8->GPyOpt) (1.12.0)\n",
            "Collecting paramz>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/37/4abbeb78d30f20d3402887f46e6e9f3ef32034a9dea65d243654c82c8553/paramz-0.9.5.tar.gz (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy>=1.8->GPyOpt) (4.4.2)\n",
            "Building wheels for collected packages: GPyOpt, GPy, paramz\n",
            "  Building wheel for GPyOpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPyOpt: filename=GPyOpt-1.2.6-cp36-none-any.whl size=83623 sha256=7d7b746cbed9b6b0e22d732de77f8402d5153f14ba70994e338afc5a83a8c4da\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/00/69/cfa967a125cf25e66f644be6193ad6f0edf231147879ad714f\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.9.9-cp36-cp36m-linux_x86_64.whl size=2633939 sha256=ec542c752847e38b85f48dda252568100323bd29da8d39192c6ec2bceeee0402\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/36/66/2b58860c84c9f2b51615da66bfd6feeddbc4e04d887ff96dfa\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-cp36-none-any.whl size=102552 sha256=5d5bbe391b2a67a648d18e772a1c38ab2314816981e92263adc7d4f38e942846\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/4a/0e/6e0dc85541825f991c431619e25b870d4b812c911214690cf8\n",
            "Successfully built GPyOpt GPy paramz\n",
            "Installing collected packages: paramz, GPy, GPyOpt\n",
            "Successfully installed GPy-1.9.9 GPyOpt-1.2.6 paramz-0.9.5\n",
            "Uninstalling tensorflow-2.2.0rc1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0rc1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.2.0rc1\n",
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 76kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.2.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.27.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.10.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (46.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=8a92f2c567338f48a41a8e9178481e789151894e1c82214c13bf3def8a3cae1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "Successfully installed gast-0.2.2 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAVTzH715O_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import GPy, GPyOpt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVJ2FjIX4nGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IRIS class\n",
        "class IRIS():\n",
        "    def __init__(self, l1, first_input=4, last_output=3,\n",
        "                 batch_size=10, \n",
        "                 epochs=10, \n",
        "                 validation_split=0.1):\n",
        "        self.__l1 = l1\n",
        "        self.__first_input = first_input\n",
        "        self.__last_output = last_output\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.validation_split = validation_split\n",
        "        self.__x_train, self.__x_test, self.__y_train, self.__y_test = self.iris_data()\n",
        "        self.__model = self.iris_model()\n",
        "        \n",
        "    def iris_data(self):\n",
        "        iris_data = load_iris() # load the iris dataset\n",
        "        x = iris_data.data\n",
        "        y_ = iris_data.target.reshape(-1, 1) # Convert data to a single column\n",
        "        # One Hot encode the class labels\n",
        "        encoder = OneHotEncoder(sparse=False)\n",
        "        y = encoder.fit_transform(y_)\n",
        "        # Split the data for training and testing\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.20)\n",
        "        return X_train, X_test, Y_train, Y_test\n",
        "    \n",
        "    \n",
        "    \n",
        "    def iris_model(self):\n",
        "        model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(self.__l1, input_shape=(self.__first_input,), activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(self.__last_output, activation=tf.nn.softmax),\n",
        "        ])\n",
        "        \n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "    \n",
        "    def iris_fit(self):        \n",
        "        self.__model.fit(self.__x_train, self.__y_train,\n",
        "                       batch_size=self.batch_size,\n",
        "                       epochs=self.epochs,\n",
        "                       verbose=0,\n",
        "                       validation_split=self.validation_split)\n",
        "    \n",
        "    def iris_evaluate(self):\n",
        "        self.iris_fit()   \n",
        "        evaluation = self.__model.evaluate(self.__x_test, self.__y_test, batch_size=self.batch_size, verbose=0)\n",
        "        return evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSg-cQLp4nGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_iris(l1=512, first_input=4, last_output=3,\n",
        "              batch_size=10, epochs=1, validation_split=0.1):\n",
        "    \n",
        "    _iris = IRIS(l1 = l1, first_input=first_input, last_output=last_output,\n",
        "                   batch_size=batch_size, epochs=epochs, \n",
        "                   validation_split=validation_split)\n",
        "    iris_evaluation = _iris.iris_evaluate()\n",
        "    return iris_evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU-qN2l04nGT",
        "colab_type": "code",
        "outputId": "7e20b3d5-caeb-4fe6-84d6-7478176b08f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# the bounds dict should be in order of continuous type and then discrete type\n",
        "domain = [{'name': 'validation_split', 'type': 'continuous',  'domain': (0.1, 0.3)},\n",
        "          {'name': 'batch_size',       'type': 'discrete',    'domain': (10, 50)},\n",
        "          {'name': 'epochs',           'type': 'discrete',    'domain': (5, 10, 20)},\n",
        "          {'name': 'l1',               'type': 'discrete',    'domain': (64, 128, 256, 512, 1024)}\n",
        "]\n",
        "\n",
        "def f(x):\n",
        "    print(\"values on domain: \", x)\n",
        "    evaluation = run_iris(\n",
        "        batch_size = int(x[:,1]), \n",
        "        epochs = int(x[:,2]), \n",
        "        l1 = int(x[:,3]),\n",
        "        validation_split = float(x[:,0]))\n",
        "    print(\"LOSS:\\t{0} \\t ACCURACY:\\t{1}\".format(evaluation[0], evaluation[1]))\n",
        "    print(evaluation)\n",
        "    print(\"\\n\")\n",
        "    return evaluation[0]\n",
        "\n",
        "# optimizer\n",
        "opt_iris = GPyOpt.methods.BayesianOptimization(f=f, domain=domain)\n",
        "opt_iris.run_optimization(max_iter=10)\n",
        "        \n",
        "opt_iris.plot_acquisition()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "values on domain:  [[ 0.10199806 50.         10.         64.        ]]\n",
            "LOSS:\t1.1248494386672974 \t ACCURACY:\t0.30000001192092896\n",
            "[1.1248494386672974, 0.3]\n",
            "\n",
            "\n",
            "values on domain:  [[  0.1630928  10.          5.        128.       ]]\n",
            "LOSS:\t0.7495896021525065 \t ACCURACY:\t0.6000000238418579\n",
            "[0.7495896021525065, 0.6]\n",
            "\n",
            "\n",
            "values on domain:  [[  0.19555108  10.          10.         128.        ]]\n",
            "LOSS:\t0.5148189067840576 \t ACCURACY:\t1.0\n",
            "[0.5148189067840576, 1.0]\n",
            "\n",
            "\n",
            "values on domain:  [[2.47300516e-01 5.00000000e+01 2.00000000e+01 1.02400000e+03]]\n",
            "LOSS:\t0.39376893639564514 \t ACCURACY:\t0.8999999761581421\n",
            "[0.39376893639564514, 0.9]\n",
            "\n",
            "\n",
            "values on domain:  [[  0.2183978  10.         10.        128.       ]]\n",
            "LOSS:\t0.504764715830485 \t ACCURACY:\t0.699999988079071\n",
            "[0.504764715830485, 0.7]\n",
            "\n",
            "\n",
            "values on domain:  [[2.46504962e-01 5.00000000e+01 1.00000000e+01 1.02400000e+03]]\n",
            "LOSS:\t0.5537739992141724 \t ACCURACY:\t0.7333333492279053\n",
            "[0.5537739992141724, 0.73333335]\n",
            "\n",
            "\n",
            "values on domain:  [[2.40826566e-01 5.00000000e+01 5.00000000e+00 1.02400000e+03]]\n",
            "LOSS:\t0.7247555255889893 \t ACCURACY:\t0.699999988079071\n",
            "[0.7247555255889893, 0.7]\n",
            "\n",
            "\n",
            "values on domain:  [[1.000e-01 5.000e+01 2.000e+01 1.024e+03]]\n",
            "LOSS:\t0.45285898447036743 \t ACCURACY:\t0.7333333492279053\n",
            "[0.45285898447036743, 0.73333335]\n",
            "\n",
            "\n",
            "values on domain:  [[  0.29659252  10.          20.         128.        ]]\n",
            "LOSS:\t0.36607207854588825 \t ACCURACY:\t0.9333333373069763\n",
            "[0.36607207854588825, 0.93333334]\n",
            "\n",
            "\n",
            "values on domain:  [[1.00e-01 1.00e+01 2.00e+01 1.28e+02]]\n",
            "LOSS:\t0.33139873544375104 \t ACCURACY:\t1.0\n",
            "[0.33139873544375104, 1.0]\n",
            "\n",
            "\n",
            "values on domain:  [[  0.22323637  50.          10.         128.        ]]\n",
            "LOSS:\t0.7280102968215942 \t ACCURACY:\t0.7333333492279053\n",
            "[0.7280102968215942, 0.73333335]\n",
            "\n",
            "\n",
            "values on domain:  [[2.40393793e-01 1.00000000e+01 1.00000000e+01 1.02400000e+03]]\n",
            "LOSS:\t0.22716544071833292 \t ACCURACY:\t0.8999999761581421\n",
            "[0.22716544071833292, 0.9]\n",
            "\n",
            "\n",
            "values on domain:  [[1.000e-01 1.000e+01 1.000e+01 1.024e+03]]\n",
            "LOSS:\t0.2586296002070109 \t ACCURACY:\t1.0\n",
            "[0.2586296002070109, 1.0]\n",
            "\n",
            "\n",
            "values on domain:  [[3.000e-01 1.000e+01 1.000e+01 1.024e+03]]\n",
            "LOSS:\t0.35475675761699677 \t ACCURACY:\t0.9666666388511658\n",
            "[0.35475675761699677, 0.96666664]\n",
            "\n",
            "\n",
            "values on domain:  [[1.000e-01 1.000e+01 2.000e+01 1.024e+03]]\n",
            "LOSS:\t0.10295619815587997 \t ACCURACY:\t1.0\n",
            "[0.10295619815587997, 1.0]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW7vai3cBtDO",
        "colab_type": "code",
        "outputId": "8bbfa3d1-11a5-419a-8122-5f4a2479d4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print(\"\"\"\n",
        "Optimized Parameters:\n",
        "\\t{0}:\\t{1}\n",
        "\\t{2}:\\t{3}\n",
        "\\t{4}:\\t{5}\n",
        "\\t{6}:\\t{7}\n",
        "\"\"\".format(domain[0][\"name\"], opt_iris.x_opt[0],\n",
        "           domain[1][\"name\"], opt_iris.x_opt[1],\n",
        "           domain[2][\"name\"], opt_iris.x_opt[2],\n",
        "           domain[3][\"name\"], opt_iris.x_opt[3]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Optimized Parameters:\n",
            "\tvalidation_split:\t0.1\n",
            "\tbatch_size:\t10.0\n",
            "\tepochs:\t20.0\n",
            "\tl1:\t1024.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oinQ1f9g72-",
        "colab_type": "code",
        "outputId": "df680bcd-6099-4108-e50f-1d69b474bca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"optimized loss: {0}\".format(opt_iris.fx_opt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "optimized loss: 0.10295619815587997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a3b-zwphkQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkGhy9pWtav-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree        #importing subpackage from sklearn library\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F94xyCzplKzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43EuYRS8F-07",
        "colab_type": "code",
        "outputId": "17fe3b7e-52a7-4c09-cbc2-16822e9592e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "criteria = [\"gini\", \"entropy\"]      #criteria to be tested\n",
        "min_sample_split_range = [2,10, 20] #min sample split to be tested\n",
        "max_depth_range = [None, 2, 5, 10]  #max depth to be tested\n",
        "min_samples_leaf_range = [1, 5, 10] #min samples in the leaf to be tested\n",
        "min_leaf_nodes_range = [None, 5, 10, 20]    #min leaf nodes to be tested\n",
        "\n",
        "param_grid = {\"criterion\": criteria,\n",
        "              \"min_samples_split\": min_sample_split_range,\n",
        "              \"max_depth\": max_depth_range,\n",
        "              \"min_samples_leaf\": min_samples_leaf_range,\n",
        "              \"max_leaf_nodes\": min_leaf_nodes_range\n",
        "                }\n",
        "\n",
        "grid = GridSearchCV(estimator=tree.DecisionTreeClassifier(), \n",
        "                    param_grid=param_grid, \n",
        "                    cv = 5, \n",
        "                    scoring='accuracy', \n",
        "                    refit=True)     #setting grid with estimator\n",
        "\n",
        "tree_model = make_pipeline(preprocessing.StandardScaler(), grid)    #creating preprocessing\n",
        "tree_model.fit(iris.data, iris.target)      #fitting data\n",
        "\n",
        "print(\"Accuracy of the tuned model: %.4f\" %grid.best_score_)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the tuned model: 0.9733\n",
            "{'criterion': 'gini', 'max_depth': None, 'max_leaf_nodes': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WurvnOCeGx1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(64,), (128,), (256,), (512,), (1024,)],\n",
        "    'batch_size':[10, 50],\n",
        "    'max_iter': [5, 10, 20]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze-TDxm3L8B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "x = iris.data\n",
        "y_ = iris.target.reshape(-1, 1) # Convert data to a single column\n",
        "# One Hot encode the class labels\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y = encoder.fit_transform(y_)\n",
        "# Split the data for training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX-GqW21_oX2",
        "colab_type": "code",
        "outputId": "c68e6553-3254-46c0-a8c0-00ab3d367705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "mlp = MLPClassifier(solver = 'adam', validation_fraction = 0.1)\n",
        "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
        "clf.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state=None, shuffle=True,\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'batch_size': [10, 50],\n",
              "                         'hidden_layer_sizes': [(64,), (128,), (256,), (512,),\n",
              "                                                (1024,)],\n",
              "                         'max_iter': [5, 10, 20]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap06U5e0pEad",
        "colab_type": "code",
        "outputId": "0a50d4be-a101-4359-a1d5-0eccee4cf0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "# Best paramete set\n",
        "print('Best parameters found:\\n', clf.best_params_)\n",
        "\n",
        "# All results\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            " {'batch_size': 10, 'hidden_layer_sizes': (1024,), 'max_iter': 20}\n",
            "0.308 (+/-0.201) for {'batch_size': 10, 'hidden_layer_sizes': (64,), 'max_iter': 5}\n",
            "0.483 (+/-0.366) for {'batch_size': 10, 'hidden_layer_sizes': (64,), 'max_iter': 10}\n",
            "0.683 (+/-0.047) for {'batch_size': 10, 'hidden_layer_sizes': (64,), 'max_iter': 20}\n",
            "0.417 (+/-0.232) for {'batch_size': 10, 'hidden_layer_sizes': (128,), 'max_iter': 5}\n",
            "0.658 (+/-0.062) for {'batch_size': 10, 'hidden_layer_sizes': (128,), 'max_iter': 10}\n",
            "0.683 (+/-0.047) for {'batch_size': 10, 'hidden_layer_sizes': (128,), 'max_iter': 20}\n",
            "0.433 (+/-0.309) for {'batch_size': 10, 'hidden_layer_sizes': (256,), 'max_iter': 5}\n",
            "0.683 (+/-0.047) for {'batch_size': 10, 'hidden_layer_sizes': (256,), 'max_iter': 10}\n",
            "0.683 (+/-0.047) for {'batch_size': 10, 'hidden_layer_sizes': (256,), 'max_iter': 20}\n",
            "0.658 (+/-0.062) for {'batch_size': 10, 'hidden_layer_sizes': (512,), 'max_iter': 5}\n",
            "0.683 (+/-0.047) for {'batch_size': 10, 'hidden_layer_sizes': (512,), 'max_iter': 10}\n",
            "0.708 (+/-0.085) for {'batch_size': 10, 'hidden_layer_sizes': (512,), 'max_iter': 20}\n",
            "0.608 (+/-0.085) for {'batch_size': 10, 'hidden_layer_sizes': (1024,), 'max_iter': 5}\n",
            "0.675 (+/-0.041) for {'batch_size': 10, 'hidden_layer_sizes': (1024,), 'max_iter': 10}\n",
            "0.750 (+/-0.082) for {'batch_size': 10, 'hidden_layer_sizes': (1024,), 'max_iter': 20}\n",
            "0.225 (+/-0.601) for {'batch_size': 50, 'hidden_layer_sizes': (64,), 'max_iter': 5}\n",
            "0.208 (+/-0.484) for {'batch_size': 50, 'hidden_layer_sizes': (64,), 'max_iter': 10}\n",
            "0.375 (+/-0.471) for {'batch_size': 50, 'hidden_layer_sizes': (64,), 'max_iter': 20}\n",
            "0.200 (+/-0.216) for {'batch_size': 50, 'hidden_layer_sizes': (128,), 'max_iter': 5}\n",
            "0.108 (+/-0.306) for {'batch_size': 50, 'hidden_layer_sizes': (128,), 'max_iter': 10}\n",
            "0.217 (+/-0.306) for {'batch_size': 50, 'hidden_layer_sizes': (128,), 'max_iter': 20}\n",
            "0.108 (+/-0.306) for {'batch_size': 50, 'hidden_layer_sizes': (256,), 'max_iter': 5}\n",
            "0.058 (+/-0.103) for {'batch_size': 50, 'hidden_layer_sizes': (256,), 'max_iter': 10}\n",
            "0.608 (+/-0.118) for {'batch_size': 50, 'hidden_layer_sizes': (256,), 'max_iter': 20}\n",
            "0.008 (+/-0.024) for {'batch_size': 50, 'hidden_layer_sizes': (512,), 'max_iter': 5}\n",
            "0.392 (+/-0.340) for {'batch_size': 50, 'hidden_layer_sizes': (512,), 'max_iter': 10}\n",
            "0.683 (+/-0.047) for {'batch_size': 50, 'hidden_layer_sizes': (512,), 'max_iter': 20}\n",
            "0.225 (+/-0.141) for {'batch_size': 50, 'hidden_layer_sizes': (1024,), 'max_iter': 5}\n",
            "0.683 (+/-0.047) for {'batch_size': 50, 'hidden_layer_sizes': (1024,), 'max_iter': 10}\n",
            "0.667 (+/-0.047) for {'batch_size': 50, 'hidden_layer_sizes': (1024,), 'max_iter': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e2DtOPtz9u-",
        "colab_type": "code",
        "outputId": "0f3206c2-19ee-4852-ea61-5cb721625bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "y_true, y_pred = Y_test , clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Results on the test set:')\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.75      0.86         8\n",
            "\n",
            "   micro avg       1.00      0.90      0.95        30\n",
            "   macro avg       1.00      0.89      0.94        30\n",
            "weighted avg       1.00      0.90      0.94        30\n",
            " samples avg       0.90      0.90      0.90        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikrvc-Jg0Hqq",
        "colab_type": "code",
        "outputId": "cf478a08-f851-41df-ee06-25ab873232e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Accuracy of the tuned model: %.4f\" %clf.best_score_)\n",
        "print(clf.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the tuned model: 0.7500\n",
            "{'batch_size': 10, 'hidden_layer_sizes': (1024,), 'max_iter': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztvk38B_3r6X",
        "colab_type": "code",
        "outputId": "6670f24f-1ac3-4d5e-e9bc-d166800fe71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.score(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YftDJxxGCNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wctyFxRAIQ7J",
        "colab_type": "code",
        "outputId": "d8bc3b7f-5c68-4069-e555-a34b8794e163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "random = RandomizedSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
        "random.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           random...fle=True,\n",
              "                                           solver='adam', tol=0.0001,\n",
              "                                           validation_fraction=0.1,\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'batch_size': [10, 50],\n",
              "                                        'hidden_layer_sizes': [(64,), (128,),\n",
              "                                                               (256,), (512,),\n",
              "                                                               (1024,)],\n",
              "                                        'max_iter': [5, 10, 20]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JLY5Qf6Ip1X",
        "colab_type": "code",
        "outputId": "c3ad60bc-1b00-4265-aeaf-076fc8535de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# Best paramete set\n",
        "print('Best parameters found:\\n', random.best_params_)\n",
        "\n",
        "# All results\n",
        "means = random.cv_results_['mean_test_score']\n",
        "stds = random.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, random.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            " {'max_iter': 20, 'hidden_layer_sizes': (1024,), 'batch_size': 10}\n",
            "0.108 (+/-0.306) for {'max_iter': 5, 'hidden_layer_sizes': (1024,), 'batch_size': 50}\n",
            "0.508 (+/-0.295) for {'max_iter': 5, 'hidden_layer_sizes': (256,), 'batch_size': 10}\n",
            "0.108 (+/-0.306) for {'max_iter': 20, 'hidden_layer_sizes': (64,), 'batch_size': 50}\n",
            "0.667 (+/-0.047) for {'max_iter': 20, 'hidden_layer_sizes': (256,), 'batch_size': 50}\n",
            "0.667 (+/-0.047) for {'max_iter': 10, 'hidden_layer_sizes': (128,), 'batch_size': 10}\n",
            "0.708 (+/-0.085) for {'max_iter': 20, 'hidden_layer_sizes': (1024,), 'batch_size': 10}\n",
            "0.117 (+/-0.262) for {'max_iter': 20, 'hidden_layer_sizes': (128,), 'batch_size': 50}\n",
            "0.458 (+/-0.366) for {'max_iter': 10, 'hidden_layer_sizes': (512,), 'batch_size': 50}\n",
            "0.108 (+/-0.306) for {'max_iter': 5, 'hidden_layer_sizes': (256,), 'batch_size': 50}\n",
            "0.125 (+/-0.147) for {'max_iter': 5, 'hidden_layer_sizes': (64,), 'batch_size': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KAg99EcIyf3",
        "colab_type": "code",
        "outputId": "ee5cb038-a7c5-431c-f07c-0f643cedc6af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "y_true, y_pred = Y_test , random.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Results on the test set:')\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "   micro avg       1.00      0.93      0.97        30\n",
            "   macro avg       1.00      0.94      0.97        30\n",
            "weighted avg       1.00      0.93      0.96        30\n",
            " samples avg       0.93      0.93      0.93        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgNe3xptI6XT",
        "colab_type": "code",
        "outputId": "0986b218-836a-4169-cd04-80f93d14ed18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "random.score(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9166666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDNC0h1mJAD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}